{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_state = {'left.x': 0.4678605021319262,\n",
    "'left.y': 0.2758423627645942,\n",
    "'left.z': 1.4101639137209923,\n",
    "'box.x': 0.6724999615580194,\n",
    "'box.y': 0.12650004790603953,\n",
    "'box.z': 0.7750041578049789}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46760835089680497"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_diss = (full_state['left.x'] - full_state['box.x'])**2 + (full_state['left.y'] - full_state['box.y'])**2 + (full_state['left.z'] - full_state['box.z'])**2\n",
    "left_diss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_state['a'] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1.0,\n",
       " 'box.x': 0.6724999615580194,\n",
       " 'box.y': 0.12650004790603953,\n",
       " 'box.z': 0.7750041578049789,\n",
       " 'left.x': 0.4678605021319262,\n",
       " 'left.y': 0.2758423627645942,\n",
       " 'left.z': 1.4101639137209923}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import os\n",
    "import sys\n",
    "import inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "sys.path.append(os.path.join(currentdir, currentdir+'/../'))\n",
    "sys.path.append(os.path.join(currentdir, currentdir+'/../RL_brain'))\n",
    "sys.path.append(os.path.join(currentdir, currentdir+'/../RL_brain/pointnet2/'))\n",
    "import tensorflow.contrib as tc\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pointnet2.utils.tf_utils as tf_utils\n",
    "from pointnet2.utils.pointnet_util import pointnet_sa_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(point_cloud, is_training=True, bn_decay=None):\n",
    "    \"\"\" PointNet 特征抽取网络, input is BxNx3, output.shape(batch_size, -1) \"\"\"\n",
    "    batch_size = point_cloud.shape[0]\n",
    "    num_point = point_cloud.shape[1]\n",
    "    end_points = {}\n",
    "    l0_xyz = point_cloud\n",
    "    l0_points = None\n",
    "    end_points['l0_xyz'] = l0_xyz\n",
    "\n",
    "    # Set abstraction layers\n",
    "    # Note: When using NCHW for layer 2, we see increased GPU memory usage (in TF1.4).\n",
    "    # So we only use NCHW for layer 1 until this issue can be resolved.\n",
    "    l1_xyz, l1_points, l1_indices = pointnet_sa_module(l0_xyz, l0_points, npoint=512, radius=0.2, nsample=32, mlp=[64,64,128], mlp2=None, group_all=False, is_training=is_training, bn_decay=bn_decay, scope='layer1', use_nchw=True)\n",
    "    l2_xyz, l2_points, l2_indices = pointnet_sa_module(l1_xyz, l1_points, npoint=128, radius=0.4, nsample=64, mlp=[128,128,256], mlp2=None, group_all=False, is_training=is_training, bn_decay=bn_decay, scope='layer2')\n",
    "    l3_xyz, l3_points, l3_indices = pointnet_sa_module(l2_xyz, l2_points, npoint=None, radius=None, nsample=None, mlp=[256,512,1024], mlp2=None, group_all=True, is_training=is_training, bn_decay=bn_decay, scope='layer3')\n",
    "\n",
    "    # Fully connected layers\n",
    "    net = tf.reshape(l3_points, [batch_size, -1])\n",
    "    return net, end_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "observe_pcl = tf.zeros((1,1024,3))\n",
    "observe_image = tf.zeros((1,256,256,3))\n",
    "trainable=True\n",
    "is_training=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-4-9e04cff98905>:14: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/baxter/catkin_ws/src/suelab_bax_arm/scripts/Baxter_env/../RL_brain/pointnet2/utils/pointnet_util.py:127: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From <ipython-input-4-9e04cff98905>:23: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n"
     ]
    }
   ],
   "source": [
    "normalizer_fn = tc.layers.layer_norm\n",
    "conv_1 = tc.layers.conv2d(inputs=observe_image, num_outputs=32, kernel_size=3,\n",
    "                                      stride=2, padding='valid', trainable=trainable, normalizer_fn=normalizer_fn)\n",
    "conv_2 = tc.layers.conv2d(inputs=conv_1, num_outputs=32, kernel_size=3,\n",
    "                                      stride=2, padding='valid', trainable=trainable, normalizer_fn=normalizer_fn)\n",
    "conv_3 = tc.layers.conv2d(inputs=conv_2, num_outputs=32, kernel_size=3,\n",
    "                                      stride=2, padding='valid', trainable=trainable, normalizer_fn=normalizer_fn)\n",
    "conv_4 = tc.layers.conv2d(inputs=conv_3, num_outputs=56, kernel_size=5,\n",
    "                                      stride=2, padding='valid', trainable=trainable, normalizer_fn=normalizer_fn)\n",
    "conv_5 = tc.layers.conv2d(inputs=conv_4, num_outputs=128, kernel_size=5,\n",
    "                                      stride=2, padding='valid', trainable=trainable, normalizer_fn=normalizer_fn)\n",
    "conv_6 = tc.layers.conv2d(inputs=conv_5, num_outputs=256, kernel_size=5,\n",
    "                                      stride=2, padding='valid', trainable=trainable, normalizer_fn=normalizer_fn)\n",
    "flatten_layer_image = tf.layers.flatten(conv_6)\n",
    "\n",
    "# pointnet2 抽取特征\n",
    "flatten_layer_pcl, end_points = get_model(point_cloud=observe_pcl,\n",
    "                                   is_training=is_training,\n",
    "                                   bn_decay=None) # end_points 占时不知道干什么用\n",
    "\n",
    "connected_layer = tf.concat([flatten_layer_image, flatten_layer_pcl], axis=1)\n",
    "\n",
    "dense_1 = tf.layers.dense(connected_layer, units=512, activation=None, trainable=trainable)\n",
    "dense_1 = tc.layers.layer_norm(dense_1, center=True, scale=True)\n",
    "dense_1 = tf.nn.relu(dense_1)\n",
    "\n",
    "dense_2 = tf.layers.dense(dense_1, units=256, activation=None, trainable=trainable)\n",
    "dense_2 = tc.layers.layer_norm(dense_2, center=True, scale=True)\n",
    "dense_2 = tf.nn.relu(dense_2)\n",
    "\n",
    "dense_3 = tf.layers.dense(dense_2, units=256, activation=None, trainable=trainable)\n",
    "dense_3 = tc.layers.layer_norm(dense_3, center=True, scale=True)\n",
    "dense_3 = tf.nn.relu(dense_3)\n",
    "\n",
    "dense_4 = tf.layers.dense(dense_3, units=256, activation=None, trainable=trainable)\n",
    "dense_4 = tc.layers.layer_norm(dense_4, center=True, scale=True)\n",
    "dense_4 = tf.nn.relu(dense_4)\n",
    "\n",
    "action_output = tf.layers.dense(dense_4, units=6, activation=tf.nn.tanh,\n",
    "                                kernel_initializer=tf.initializers.random_uniform(minval=-0.003,\n",
    "                                                                                  maxval=0.003), trainable=trainable)\n",
    "\n",
    "#输出(1,4)\n",
    "action_output = action_output * np.array([0.05, 0.05, 0.05, np.radians(90),np.radians(90),np.radians(90)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    print sess.run(action_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "p = np.zeros((1024,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "a=tf.constant(np.tile(np.array([0,0,0]).reshape((1,1,3)), (32,2,5)),dtype=tf.float32) # (batch_size, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "observe = {'pcl':np.array([[1,2],[3,4]]), 'image':np.array([[1,2],[3,4]])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(observe) == dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_min2d(x): # 加入demo 时候也要注意 数据类型\n",
    "    if type(x) == dict:\n",
    "        return x\n",
    "        pass\n",
    "    else:\n",
    "        x = np.array(x, dtype=np.float32)\n",
    "        if x.ndim >= 2:\n",
    "            return x\n",
    "        else:\n",
    "            return x.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "elem_enumer = ((0, 'observe0_img'),(1, 'observe0_pcl'),\n",
    "         (2, 'observe1_img'),(3, 'observe1_pcl'),\n",
    "         (4, 'actions'),(5, 'rewards'),\n",
    "         (6, 'full_states0'),(7, 'full_states1'),(8, 'terminals1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'observe0_img')\n",
      "(1, 'observe0_pcl')\n",
      "(2, 'observe1_img')\n",
      "(3, 'observe1_pcl')\n",
      "(4, 'actions')\n",
      "(5, 'rewards')\n",
      "(6, 'full_states0')\n",
      "(7, 'full_states1')\n",
      "(8, 'terminals1')\n"
     ]
    }
   ],
   "source": [
    "for j, element_class in enumerate(a):\n",
    "    print (j, element_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ['observe0_img','observe0_pcl','observe1_img','observe1_pcl','actions','rewards','full_states0','full_states1','terminals1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "from geo import *\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "leap_2_base = FRAME(xyzrpy = [0.750000, 0.000000,\n",
    "        -0.129000, 1.57079632679, 0, -1.57079632679])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.75, 0.0, -0.129, 1.57079632679, -0.0, -1.57079632679]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leap_2_base.xyzrpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7500000000024483, -0.5, -0.129, 0.0, -0.0, -1.57079632679]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leap_2_base.__mul__(FRAME(xyzrpy = [0.5, 0.000000,\n",
    "    0.0, 0., 0., 0.])).xyzrpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.25,\n",
       " 2.4482944300733737e-12,\n",
       " -0.1290000000024483,\n",
       " 1.57079632679,\n",
       " -0.0,\n",
       " -1.57079632679]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leap_2_base.__mul__(FRAME(xyzrpy = [0., 0.000000,\n",
    "    -0.5, 0, 0, 0.])).xyzrpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.75, 0.0, -0.629, 1.57079632679, -0.0, -1.57079632679]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FRAME(xyzrpy = [0., 0.000000,\n",
    "    -0.5, 0, 0, 0.]).__mul__(base_2_leap).xyzrpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
